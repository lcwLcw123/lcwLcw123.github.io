
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Chaowei Liu's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Chaowei Liu is currently a master in Learning and vision Lab">
  <meta name="keywords" content="Chaowei Liu, 刘朝玮">
  <meta name="author" content="Chaowei Liu" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/android-chrome-192x192.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width: 150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>CHAOWEI</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#projects" class="w3-bar-item w3-button">Projects</a>
    <!-- <a href="#talks" class="w3-bar-item w3-button">Talks</a> -->
    <a href="#Publications" class="w3-bar-item w3-button">Publications</a>
    <!-- <a href="#service" class="w3-bar-item w3-button">Services</a> -->
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">CHAOWEI</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/Lcw_image.png">
      <h1>Chaowei Liu</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am now a master in National University of Singapore, attending <a href="http://lv-nus.org/">Learning and Vision Lab</a>, where I was advised by Prof. <a href="https://cde.nus.edu.sg/ece/staff/wang-xinchao/">Xinchao Wang</a></a>. Before that, I finish my bachelor degree at school of EE, <a href="http://en.hitsz.edu.cn/">HARBIN INSTITUTE OF TECHNOLOGY, SHENZHEN</a>. I am interested in Low-level vision, Graph Neural Network, Diffusion Model and LLM etc.
        <p class="w3-center">
          <a href="mailto:e1011116@u.nus.edu">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com.hk/citations?hl=zh-CN&authuser=1&user=XzYtb7QAAAAJ">Google Scholar</a>&nbsp/&nbsp
          <a href="data\CV.pdf">CV</a>&nbsp/&nbsp
          <a href="data\transcript(1)">Transcripts</a>  
        </p>
        </tbody></table>
  </div>
<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> <a style="color:red">07/2023, I am currently seeking suitable PhD and internship positions. If there are any appropriate opportunities, please feel free to drop me an email. I would greatly appreciate it! </a>.</li></p>
      <p><li> 10/2023, Discover how to restore document images under various degradation conditions and transform them into a PDF-like quality. See our newest paper for more insights. <a href="https://arxiv.org/abs/2310.17910">DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF</a></li></p>
      <p><li> 05/2023, Our team NUS-LV Bokeh attend  <a href="https://codalab.lisn.upsaclay.fr/competitions/10229"> NTIRE 2023 Bokeh Effect Transformation Challenge</a></a>, and we are proud to announce that we secured  <strong>third place</strong>.</a></li></p>
      <p><li> 04/2023, Customize your chatgpt for code tasks is now possible, see our newest paper <a href="https://arxiv.org/abs/2303.03012">the Feasibility of Specialized Ability Stealing for Large Language Code Models</a></a>.</li></p>


  </div>
<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>

  <h4><li>DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF</li></h4>
  <p class="w3-justify">
    For capturing colored document images, e.g. posters and magazines, it is common that multiple degradations such as shadows, wrinkles, etc., are simultaneously introduced due to external factors. Restoring multi-degraded
    colored document images is a great challenge, yet overlooked, as most existing algorithms focus on enhancing
    color ignored document images via binarization. Thus, we propose DocStormer, a novel algorithm designed to re
    store multi-degraded colored documents to their potential pristine PDF. The contributions are: firstly, we propose a
    “Perceive-then-Restore” paradigm with a reinforced transformer block, which more effectively encodes and utilizes
    the distribution of degradations. Secondly, we are the first to utilize GAN and pristine PDF magazine images to nar
    row the distribution gap between the enhanced results and PDF images, in pursuit of less degradation and better vi
    sual quality. Thirdly, we propose a non-parametric strategy, PFILI, which enables a smaller training scale and larger
    testing resolutions with acceptable detail trade off, while saving memory and inference time. Fourthly, we are the first
    to propose a novel Multi-Degraded Colored Document image Enhancing dataset, named MD-CDE, for both training
    and evaluation. Experimental results show that the DocStormer exhibits superior performance, capable of revital
    izing multi-degraded colored documents into their potential pristine digital versions, which fills the current academic
    gap from the perspective of method, data, and task.
  </p>
        <img style="width:80%;" src="images\Docstormer_overview.jpg"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://arxiv.org/abs/2310.17910">Paper</a>
        </p>
	
	<h4><li>CBTNet:a controllable bokeh transformation model</li></h4>
  <p class="w3-justify">
    We have conducted significant work in the realm of computational photography on mobile devices. We have proposed CBTNET, a controllable bokeh transformation model. This model is designed to convert the bokeh effect of one lens to the effect of another lens, while preserving the sharpness of the foreground regions in the image.
  </p>
        <img style="width:80%;" src="images/render.png"> 
        <img style="width:80%;" src="images/CBTnet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/lcwLcw123/BKchallenge">Code</a> | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Conde_Lens-to-Lens_Bokeh_Effect_Transformation._NTIRE_2023_Challenge_Report_CVPRW_2023_paper.html">Paper</a>
        </p>
        <h4><li>Research on data augmentation strategy of graph neural network</li></h4>
        <p class="w3-justify"></p>
        We propose a new data augmentation strategy of graph neural network based on changing feature matrix. Achieve up to 7% absolute F1 performance improvements across architectures and datasets.
        </p>
        <img style="width:60%;" src="images/gnn.png"> 
  </div>

  
  <div class="w3-container w3-padding-32" id="Publications">
    <h2>Publications</h2>
      <p class="w3-left-align" style="line-height:200%">
        I am interested in Low-level vision, Graph Neural Network, Diffusion Model and LLM etc.
      </p>
    <h4> Conference Papers:</h4>
      
      <p>
      <li><strong>DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF</strong>
      <br>
      <strong>Chaowei Liu</strong>, Jichun Li, Yihua Teng, Chaoqun Wang, Nuo Xu, Jihao Wu, Dandan Tu
      <br>
      <em>Arixv </em>| <a style="color: #447ec9" href="https://arxiv.org/abs/2310.17910">paper</a>
      <!-- <a style="color: #447ec9" href="https://github.com/">code</a> | <span style="color:red">Oral Presentation</span>  -->
      </p>

      <li><strong>On the Feasibility of Specialized Ability Extracting for Large Language Code Models</strong>
      <br>
      Zongjie Li, Chaozheng Wang, Pingchuan Ma, <strong>Chaowei Liu</strong>, Shuai Wang, Daoyuan Wu, Cuiyun Gao
      <br>
      <em>ICSE</em> 2024  <strong>CCF-A</strong>| <a style="color: #447ec9" href="https://arxiv.org/abs/2303.03012">paper</a>

      </ol>
      
    <h4> Challenge Reports:</h4>

      <ol>
        <p>
        
        <li><strong>Lens-to-Lens Bokeh Effect Transformation. NTIRE 2023 Challenge Report</strong>
        <br>
        <em>CVPRWorkshop</em> 2023  <strong> Third Place</strong>| <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Conde_Lens-to-Lens_Bokeh_Effect_Transformation._NTIRE_2023_Challenge_Report_CVPRW_2023_paper.html">paper</a>
        <br>
        </ol>

    </p>
  </div>

<!-- The Services Section -->
  <!-- <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Area Chair of <a href="https://nips.cc/Conferences/2023/">NeurIPS 2023</a>, <a href="https://icml.cc/Conferences/2023">ICML 2023</a>, <a href="https://nips.cc/Conferences/2022/">NeurIPS 2022</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Action Editor of <a href="https://jmlr.org/tmlr/">TMLR (Transactions on Machine Learning Research)</a>.</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
  </div> -->

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2022, Outstanding Graduates(10%).</p>
    <p><li> 2022, Outstanding Graduation Project(10%).</p>
    <p><li> 2020, First Prize in National College Students’ Innovation & Entrepreneurship Training Projec.</p>
  </div>  
  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=CCI1G88YZZEM5tUtj84-t7BBeDwcUXvumDdAjMPGoTg&cl=ffffff&w=a"></script>
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>


